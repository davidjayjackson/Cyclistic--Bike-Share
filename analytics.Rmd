---
title: 'Cyclistic Bike Share: Analytics'
author: "David Jackson"
date: "`r Sys.time()`"
output: 
  pdf_document: 
    fig_width: 9
    fig_height: 6
---

```{r setup, include=FALSE,echo=FALSE,error=FALSE,message=FALSE}
knitr::opts_chunk$set(echo = FALSE,message = FALSE,error = FALSE)
library(tidyverse)
library(janitor)
library(lubridate)
library(scales)
rm(list=ls())
```



## Data Wrangling Change Log

* Date Range: 2020-04-01 to 2021--3-31

August 6, 2021:

* Total Rows: 3,489,749
* I raised the following three concerns (about the data) with Lily Moreno(The director of marketing): 
(1) 10,552 rows  with negative trip durations,
(2) 122,175 rows with missing Starting Station names (and ID),(3) As many as 1,291 stations  with two different start_staition_id.

* I was advised by Lily Moreno that we could ignore rows with trip duraton <=0.
We could also ignore rows with missing start_station_name, and also ignore stations_id. 
* And should focus on doing using the start_station_name to preform aggregate functions on date, start_station_name, member_casual and rideable_type.
* Cleaning reducted rows to 3,343,689

```{r}
##
## Import previous 12 months data
##
df1 <- read.csv("./Data/t1.csv")
df2 <- read.csv("./Data/t2.csv")
df3 <- read.csv("./Data/t3.csv")
df4 <- read.csv("./Data/t4.csv")
df5 <- read.csv("./Data/t5.csv")
df6 <- read.csv("./Data/t6.csv")
df7 <- read.csv("./Data/t7.csv")
df8 <- read.csv("./Data/t8.csv")
df9 <- read.csv("./Data/t9.csv")
df10 <- read.csv("./Data/t10.csv")
df11 <- read.csv("./Data/t11.csv")
df12 <- read.csv("./Data/t12.csv")
```
```{r}
##
## Combine 12 data.frames into One (1) data.frame
##
bike_rides <- rbind(df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12)
bike_rides <- janitor ::remove_empty(bike_rides,which = c("cols"))
bike_rides <- janitor::remove_empty(bike_rides,which = c("rows"))
bike_rides <- bike_rides  %>% filter(start_station_name !="")
``` 
```{r}
##
## Convert Data/Time stamp to Date/Time ...
##
bike_rides$Ymd <- as.Date(bike_rides$started_at)
bike_rides$started_at <- lubridate::ymd_hms(bike_rides$started_at)
bike_rides$ended_at <- lubridate::ymd_hms(bike_rides$ended_at)

bike_rides$start_hour <- lubridate::hour(bike_rides$started_at)
bike_rides$end_hour <- lubridate::hour(bike_rides$ended_at)
```

```{r}

bike_rides$Hours <- difftime(bike_rides$ended_at,bike_rides$started_at,units = c("hours"))

bike_rides$Minutes <- difftime(bike_rides$ended_at,bike_rides$started_at,units = c("mins"))

bike_rides <- bike_rides %>% filter(Minutes >0)

```
```{r}
### Create summary data frame

bikesrides2 <- bike_rides %>% group_by(Weekly = floor_date(Ymd,"week"),start_hour) %>%
                summarise(
                  Minutes = sum(Minutes),
                  Mean = mean(Minutes),
                  Median = median(Minutes),
                  Max = max(Minutes),
                  Min = min(Minutes),
                  Count = n()
                ) %>% ungroup()
```
```{r}
bikesrides2$CntMA <- forecast::ma(bikesrides2$Count,28)
```


## Plot of Rides By Date
#### Summary Stats: Counts

 * Summary of Hourly Counts

```{r}
# Summary of Hourly Counts
summary(bikesrides2$Count)
```
 
 * Count of rides by Hour

```{r}
# Table of Counts by Hour
xtabs(bikesrides2$Count~bikesrides2$start_hour)
```


```{r}
bikesrides2$Monthly <- lubridate::month(bikesrides2$Weekly)

bikesrides2 %>% ggplot() + geom_col(aes(x=Weekly,y=Count)) +
  scale_y_continuous(labels = comma) +
  labs(title = "Count of Rides per Day",
       subtitle = "(Bases on 28 day moving average",
       y="Average rides per day")  
      
```
```{r}
bikesrides2 %>% ggplot() + geom_col(aes(x=start_hour,y=Count)) +
  scale_y_continuous(labels = comma) +
  labs(title = "Count of Rides by Hours",
        y="Rides per Hour") 
      
```

## Count of Rides by Bike Type
#### Summary of Bike Types

```{r}
bikestype <- bike_rides %>% group_by(member_casual,rideable_type,Weekly = floor_date(Ymd,"week")) %>%
                summarise(
                  Minutes = sum(Minutes),
                  Mean = mean(Minutes),
                  Median = median(Minutes),
                  Max = max(Minutes),
                  Min = min(Minutes),
                  Count = n()
                ) %>% ungroup()
```

* Count by Bike Type(Total by Week)

```{r}
ggplot(bikestype) + geom_area(aes(x=Weekly,y=Count,col=rideable_type)) +
  scale_y_continuous(labels = comma) +
  labs(title="Count of Rides by Bike Type")
  
 
```

```{r}
bike_rides %>% count(start_station_name,sort = TRUE) %>%
  top_n(20) %>% ggplot() + geom_col(aes(x=reorder(start_station_name,n),y=n)) +
  coord_flip() + labs(title = "Top 20 Start Stations by Ride Count",
                      y = "Station Name",x="Count of Rides") +
  scale_y_continuous(labels = comma)
```


```{r}
ggplot(bikestype) + geom_col(aes(x=Weekly,y=Count,fill=member_casual)) +
  scale_y_continuous(labels = comma) +
  labs(title="Count of Rides by Rider Type")
  
 
```

```{r}

```

```{r}
ggplot(bikestype) + geom_col(aes(x=Weekly,y=Minutes)) +
  scale_y_continuous(labels = comma) + facet_wrap(~rideable_type) +
  labs(title="Total Ride Minutes by Week")
```
```{r}
ggplot(bikestype,aes(x=Weekly,y=Minutes,fill=rideable_type)) + 
  geom_area(stat = "identity", position = position_dodge(), alpha = 0.75) +
  scale_y_continuous(labels = comma) + 
  labs(title = "Rides Minutes by Bike Type and Week",
       y="Bike Trip In Minutes")
```

## Begin Analysis Of Minutes of Ride Time

```{r}

ggplot(bikesrides2) + geom_col(aes(x=Weekly,y=Mean)) +
  labs(title="Average Trip Minutes by Week", y ="Average Ride Time(minutes)") +
  scale_y_continuous(labels = comma)
```


